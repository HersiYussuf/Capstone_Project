{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import missingno as msno\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "# Metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score,f1_score,recall_score,mean_squared_error, r2_score, roc_auc_score, roc_curve, classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "# !pip install catboost\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modelling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\Hersi\\Videos\\Capstone legit\\Capstone_Project\\clean_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"race\"].fillna(df[\"race\"].mode()[0], inplace=True)\n",
    "df[\"race\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[-df.discharge_disposition_id.isin([11,13,14,19,20,21])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_list = ['diag_1','diag_2','diag_3']\n",
    "\n",
    "for col in diag_list:\n",
    "    df[col].fillna('NaN', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def transformFunc(value):\n",
    "    value = re.sub(\"V[0-9]*\", \"0\", value) # V \n",
    "    value = re.sub(\"E[0-9]*\", \"0\", value) # E \n",
    "    value = re.sub('NaN', \"-1\", value) # Nan \n",
    "    return value\n",
    "\n",
    "def transformCategory(value):\n",
    "    if value>=390 and value<=459 or value==785:\n",
    "        category = 'Circulatory'\n",
    "    elif value>=460 and value<=519 or value==786:\n",
    "        category = 'Respiratory'\n",
    "    elif value>=520 and value<=579 or value==787:\n",
    "        category = 'Digestive'\n",
    "    elif value==250:\n",
    "        category = 'Diabetes'\n",
    "    elif value>=800 and value<=999:\n",
    "        category = 'Injury'          \n",
    "    elif value>=710 and value<=739:\n",
    "        category = 'Musculoskeletal'   \n",
    "    elif value>=580 and value<=629 or value==788:\n",
    "        category = 'Genitourinary'\n",
    "    elif value>=140 and value<=239 :\n",
    "        category = 'Neoplasms'\n",
    "    elif value==-1:\n",
    "        category = 'NAN'\n",
    "    else :\n",
    "        category = 'Other'\n",
    "\n",
    "    return category\n",
    "\n",
    "for col in diag_list:\n",
    "    df[col] = df[col].apply(transformFunc)\n",
    "    df[col] = df[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def transformFunc(value):\n",
    "    if re.match(r'^-?\\d+(?:\\.\\d+)?$', str(value)):\n",
    "        return float(value)\n",
    "    elif value == 'NaN':\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def transformCategory(value):\n",
    "    # Rest of the code for transforming categories\n",
    "\n",
    "# Loop through the diag_list columns and apply the transformations\n",
    "    for col in diag_list:\n",
    "\n",
    "         df[col] = df[col].apply(transformFunc)\n",
    "         df[col] = df[col].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for col in diag_list:\n",
    "    df[col] = df[col].apply(transformFunc)\n",
    "    df[col] = df[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def transformFunc(value):\n",
    "    if re.match(r'^-?\\d+(?:\\.\\d+)?$', str(value)):\n",
    "        return float(value)\n",
    "    elif value == 'NaN':\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def transformCategory(value):\n",
    "    # Rest of the code for transforming categories\n",
    "\n",
    "# Apply vectorization and parallel processing for each column in diag_list\n",
    "for col in diag_list:\n",
    "    col_values = np.array(df[col])\n",
    "    \n",
    "    # Vectorization using NumPy\n",
    "    transformed_values = np.vectorize(transformCategory)(col_values)\n",
    "    df[col] = transformed_values\n",
    "    \n",
    "    # Parallel processing using joblib\n",
    "    num_cores = <specify the number of cores to use>\n",
    "    transformed_values = Parallel(n_jobs=num_cores)(\n",
    "        delayed(transformCategory)(value) for value in col_values\n",
    "    )\n",
    "    df[col] = transformed_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in diag_list:\n",
    "    df[col] = df[col].apply(transformCategory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax =plt.subplots(nrows=3,ncols=1,figsize=(15,12))\n",
    "count =0\n",
    "for i in diag_list:\n",
    "    sns.countplot(df[i], hue=df.readmitted, palette='Spectral', ax=ax[count], order = df[i].value_counts().index);\n",
    "    count = count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "clf = LocalOutlierFactor(n_neighbors = 2 , contamination = 0.1)\n",
    "clf.fit_predict(df[numerical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_scores = clf.negative_outlier_factor_\n",
    "df1_scores[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(df1_scores)[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_value = np.sort(df1_scores)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_tf = df_scores > threshold_value\n",
    "outlier_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = data[df_scores > threshold_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[df_scores < threshold_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom encoding for the 21 Drug Features\n",
    "drugs = ['metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'glipizide', 'glyburide', 'pioglitazone',\n",
    "        'rosiglitazone', 'acarbose', 'miglitol', 'insulin', 'glyburide-metformin', 'tolazamide', 'metformin-pioglitazone',\n",
    "        'metformin-rosiglitazone', 'glimepiride-pioglitazone', 'glipizide-metformin', 'troglitazone', 'tolbutamide', 'acetohexamide']\n",
    "\n",
    "for col in drugs:\n",
    "    data[col] = data[col].replace(['No','Steady','Up','Down'],[0,1,1,1])\n",
    "    data[col] = data[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A1Cresult and max_glu_serum\n",
    "data['A1Cresult'] = data['A1Cresult'].replace(['>7','>8','Norm','None'],[1,1,0,-99])\n",
    "data['max_glu_serum'] = data['max_glu_serum'].replace(['>200','>300','Norm','None'],[1,1,0,-99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot Encoding Race and Id's \n",
    "one_hot_data = pd.get_dummies(data, columns=['race'], prefix=[\"enc\"])\n",
    "\n",
    "columns_ids = ['admission_type_id', 'discharge_disposition_id', 'admission_source_id']\n",
    "\n",
    "one_hot_data[columns_ids] = one_hot_data[columns_ids].astype('str')\n",
    "one_hot_data = pd.get_dummies(one_hot_data, columns=columns_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = one_hot_data.copy()\n",
    "X = df.drop(columns=\"readmitted\", axis=1)\n",
    "Y = df.readmitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_enc = OrdinalEncoder()\n",
    "X_train.age = ordinal_enc.fit_transform(X_train.age.values.reshape(-1, 1))\n",
    "X_test.age = ordinal_enc.transform(X_test.age.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in diag_list:\n",
    "    label_enc = LabelEncoder()\n",
    "    X_train[col] = label_enc.fit_transform(X_train[col])\n",
    "    X_test[col] = label_enc.fit_transform(X_test[col]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = ['change', 'diabetesMed', 'gender']\n",
    "\n",
    "from category_encoders import BinaryEncoder\n",
    "binary_enc = BinaryEncoder(cols=binary)\n",
    "binary_enc.fit_transform(X_train)\n",
    "X_train = binary_enc.fit_transform(X_train)\n",
    "X_test = binary_enc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "X = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "not_readmitted = X[X.readmitted==0]\n",
    "readmitted = X[X.readmitted==1]\n",
    "\n",
    "not_readmitted_sampled = resample(not_readmitted,\n",
    "                                replace = False, \n",
    "                                n_samples = len(readmitted),\n",
    "                                random_state = 42)\n",
    "\n",
    "downsampled = pd.concat([not_readmitted_sampled, readmitted])\n",
    "\n",
    "downsampled.readmitted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = downsampled.readmitted\n",
    "X_train = downsampled.drop('readmitted', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train validation split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score,f1_score\n",
    "from sklearn.metrics import confusion_matrix as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_specificity(y_actual, y_pred, thresh):\n",
    "    # calculates specificity\n",
    "    return sum((y_pred < thresh) & (y_actual == 0)) /sum(y_actual ==0)\n",
    "\n",
    "def print_report(y_actual, y_pred, thresh):\n",
    "    \n",
    "    auc = roc_auc_score(y_actual, y_pred)\n",
    "    accuracy = accuracy_score(y_actual, (y_pred > thresh))\n",
    "    recall = recall_score(y_actual, (y_pred > thresh))\n",
    "    precision = precision_score(y_actual, (y_pred > thresh))\n",
    "    fscore = f1_score(y_actual,(y_pred > thresh) )\n",
    "    specificity = calc_specificity(y_actual, y_pred, thresh)\n",
    "    print('AUC:%.3f'%auc)\n",
    "    print('accuracy:%.3f'%accuracy)\n",
    "    print('recall:%.3f'%recall)\n",
    "    print('precision:%.3f'%precision)\n",
    "    print('fscore:%.3f'%fscore)\n",
    "    print('specificity:%.3f'%specificity)\n",
    "    print(' ')\n",
    "    return auc, accuracy, recall, precision,fscore, specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection: Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = LogisticRegression(solver = \"liblinear\",class_weight=\"balanced\",random_state = 42).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds = log_model.predict_proba(X_train)[:,1]\n",
    "y_val_preds = log_model.predict_proba(X_val)[:,1]\n",
    "\n",
    "print(\"Logistic Regression\")\n",
    "print('Training:')\n",
    "lr_train_auc, lr_train_accuracy, lr_train_recall, \\\n",
    "    lr_train_precision, lr_train_fscore, lr_train_specificity = print_report(y_train,y_train_preds, thresh)\n",
    "print('Validation:')\n",
    "lr_val_auc, lr_val_accuracy, lr_val_recall, \\\n",
    "    lr_val_precision,lr_val_fscore, lr_val_specificity = print_report(y_val,y_val_preds, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "predictions = log_model.predict(X_train)\n",
    "train_score = round(accuracy_score(y_train, predictions), 3)\n",
    "cm_train = cm(y_train, predictions)\n",
    "\n",
    "predictions = log_model.predict(X_val)\n",
    "val_score = round(accuracy_score(y_val, predictions), 3)\n",
    "cm_val = cm(y_val, predictions)\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(nrows=1,ncols=2,figsize=(15,5)) \n",
    "sns.heatmap(cm_train, annot=True, fmt=\".0f\",ax=ax1)\n",
    "ax1.set_xlabel('Predicted Values')\n",
    "ax1.set_ylabel('Actual Values')\n",
    "ax1.set_title('Train Accuracy Score: {0}'.format(train_score), size = 15)\n",
    "sns.heatmap(cm_val, annot=True, fmt=\".0f\",ax=ax2)\n",
    "ax2.set_xlabel('Predicted Values')\n",
    "ax2.set_ylabel('Actual Values')\n",
    "ax2.set_title('Validation Accuracy Score: {0}'.format(val_score), size = 15)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
